# Additional Resources

## Article
* [The Future of Design, Pt. 1: Body as Input: With machine learning, our bodies may be the next step in the way we interact with the internet](https://modus.medium.com/a-live-intelligent-web-how-will-we-design-for-it-part-one-21ab0f4a25e1) by ITP Human in Residence, Lisa Jamhoury

## pix2pix
* [Image-to-Image Translation with Conditional Adversarial Nets (pix2pix)](https://phillipi.github.io/pix2pix/), paper and code<br>
* [Gene Kogan The Neural Aesthetic @ ITP NYU Fall 2018 - Lecture 7: Conditional generative models](https://ml4a.github.io/classes/itp-F18/07/), a discussion and many examples of image-to-image translation techniques including pix2pix and CycleGAN
* [pix2pix](https://ml5js.org/reference/api-Pix2Pix/) in ml5.js

## SPADE
* [The Coding Train: Introduction to Runway: Machine Learning for Creators (Part 1)](https://www.youtube.com/watch?v=ARnf4ilr9Hc), an introduction to RunwayML and the pre-trained semantic image synthesis model, SPADE-COCO, which works similar to SPADE-Landscapes<br>
* [This neural net makes my sketches real](https://aiweirdness.com/post/185617397117/this-neural-net-makes-my-sketches-real) by Janelle Shane, an exploration of SPADE-COCO and SPADE-Landscapes in RunwayML

## ml5.js
* [pix2pix()](https://ml5js.org/reference/api-Pix2Pix/)
* [UNET()](https://ml5js.org/reference/api-UNET/)<br>
* [bodyPix()](https://ml5js.org/reference/api-BodyPix/)<br>
* [The Coding Train: Live Stream #184: uNet and BodyPix with ml5.js](https://www.youtube.com/watch?v=jKHgVdyC55M)

## RunwayML
* [Plugin for Photoshop](https://github.com/runwayml/RunwayML-for-Photoshop)
* [Twitter](https://twitter.com/runwayml)<br>
* [Slack](http://runwayml.com/joinslack)<br>
* [Learning Guides](https://learn.runwayml.com)<br>
