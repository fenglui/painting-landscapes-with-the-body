# Additional Resources

## Article
* [The Future of Design, Pt. 1: Body as Input: With machine learning, our bodies may be the next step in the way we interact with the internet](https://modus.medium.com/a-live-intelligent-web-how-will-we-design-for-it-part-one-21ab0f4a25e1) by ITP Human in Residence, Lisa Jamhoury

## pix2pix
* [Image-to-Image Translation with Conditional Adversarial Nets (pix2pix)](), paper and code<br>
* [Gene Kogan The Neural Aesthetic @ ITP NYU Fall 2018 - Lecture 7: Conditional generative models](), a discussion and many examples of image-to-image translation techniques including pix2pix and CycleGAN
* [pix2pix]() in ml5.js

## SPADE
* [The Coding Train: Introduction to Runway: Machine Learning for Creators (Part 1)](), an introduction to RunwayML and the pre-trained semantic image synthesis model, SPADE-COCO, which works similar to SPADE-Landscapes<br>
* [This neural net makes my sketches real]() by Janelle Shane, an exploration of SPADE-COCO and SPADE-Landscapes in RunwayML

## ml5.js
* [pix2pix()](https://ml5js.org/reference/api-Pix2Pix/)
* [UNET()](https://ml5js.org/reference/api-UNET/)<br>
* [bodyPix()](https://ml5js.org/reference/api-BodyPix/)<br>
* [The Coding Train: Live Stream #184: uNet and BodyPix with ml5.js](https://www.youtube.com/watch?v=jKHgVdyC55M)

## RunwayML
* [Twitter](https://twitter.com/runwayml)<br>
* [Slack](http://runwayml.com/joinslack)<br>
* [Learning Guides](https://learn.runwayml.com)<br>
